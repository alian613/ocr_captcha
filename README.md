# OCR CAPTCHA

This project is an OCR (Optical Character Recognition) tool for CAPTCHA verification based on PyTorch.   
It supports **training** and **evaluating** CAPTCHA recognition models and provides a simple CLI tool for generating images, training models, prediction, and evaluation.

ğŸ“– [ä¸­æ–‡èªªæ˜æ–‡ä»¶](README_zh.md)

## âœ¨ Features

- âœ… Supports CAPTCHA image generation
- âœ… Supports CUDA/GPU acceleration (automatically uses GPU if CUDA is available)
- âœ… Supports recognition using trained models
- âœ… Customizable character set, CAPTCHA length, image size, and various training parameters
- âœ… Supports prediction on single image or batch of images in a folder
- âœ… Model evaluation function to calculate accuracy
- âœ… Simple CLI interface for ease of use

---

## ğŸ’¾ Installation

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Quick Start

### 1. Generate CAPTCHA Images
   ```bash
   python generate.py
   ```

   Or use the CLI tool:
   ```base
   python main.py generate
   ```
   
   > Use --help to view available options

### 2. Train Model
   ```bash
   python train.py
   ```

   Or use the CLI tool:
   ```base
   python main.py train
   ```

   > Use --help to view available options


### 3. Predict CAPTCHA
   Place images to be recognized in `./data/pred`
   ```bash
   python predict.py ./data/pred
   ```

   Or use the CLI tool:
   ```base
   python main.py predict ./data/pred
   ```

   > Use --help to view available options

---

## ğŸ“‚ Project Structure
ocr-captcha/
â”œâ”€â”€ cli.py              # CLI entry point  
â”œâ”€â”€ config.py           # Configuration loader  
â”œâ”€â”€ config.yaml         # Default configuration file  
â”œâ”€â”€ train.py            # train the OCR model  
â”œâ”€â”€ predict.py          # predict CAPTCHA from images  
â”œâ”€â”€ evaluate.py         # Evaluates the model's accuracy  
â”œâ”€â”€ codec.py            # Handles encoding/decoding of CAPTCHA strings to tensors and vice versa  
â”œâ”€â”€ model.py            # Defines the CNN model architecture used for CAPTCHA recognition  
â”œâ”€â”€ dataset.py          # Dataset loading and preprocessing (supports memory and on-disk modes)  
â”œâ”€â”€ generate.py         # CAPTCHA image generator for training and testing  
â”œâ”€â”€ requirements.txt    # Required dependencies  
â”œâ”€â”€ data/               # Default folder for storing image datasets  
â”‚   â”œâ”€â”€ eval/           # Images used for model evaluation (default)  
â”‚   â”œâ”€â”€ pred/           # Images to be predicted (default)   
â”‚   â””â”€â”€ raw/            # Training images (default)  
â””â”€â”€ model/              # Folder to save/load trained models (default)  

---

## ğŸ’¡Tips
- Speed up training with `--cache`
> When running `train.py`, you can add the `--cache` option to load the dataset into memory (RAM),   
> which avoids reading from disk and speeds up training. Make sure your system has enough RAM available.

- Reference accuracy
> Training with `--dataset-size 100000 --epochs 30` can achieve over 99.5% accuracy on the same dataset. 
> However, accuracy may drop to around 80% when tested on a different CAPTCHA dataset.

- Beware of `--eval-acc-threshold`
> By default (as defined in `config.yaml`), the evaluation accuracy threshold is set to 75. 
> If a model evaluation result falls below this during training, 
> the current training will be skipped to save time and speed up convergence.

- Use `config.yaml` to set default parameters
> Paths, image size, CAPTCHA length, charset, and more can be configured in `config.yaml`. 
> If CLI parameters are not explicitly specified, the values from `config.yaml` will be used.


---


## ğŸ™‹â€â™€ï¸ Contact
If you have any questions or suggestions, feel free to open an issue on GitHub!


---


## â­ Support My Open Source Project
If you appreciate my work, consider â­ starring this repository or buying me a coffee to support development. 
Your support means a lot to me â€” thank you!

### [Ko-fi Support](https://ko-fi.com/alian613)


---


## ğŸ“„ License | æˆæ¬Šæ¢æ¬¾
This project is licensed under the MIT License.



